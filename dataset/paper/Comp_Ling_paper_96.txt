A type of fake news that has received little attention in the research community is manipulated text.
Manipulated text is typically created by manipulating a human written news article minimally
(e.g., replacing every occurrence of a particular entity, ‘Obama’ in a news article with another American politician entity). Current fake news detectors that exploit stylometric signals from the text
(e.g., choice of specific words to express false statements) are clearly insufficient for distinguishing
manipulated text from human written text (Zhou
et al., 2019; Schuster et al., 2020) as the style underlying the manipulated text is virtually identical
to human writing style. In this work, we focus on
this problem of distinguishing manipulated news
articles from human written news articles.
We consider a particular type of text manipulation — entity perturbation (Zhou et al., 2019),
where a manipulated news article is created by modifying a fixed number of entities in a human written news article (e.g., replacing them with entities
generated from a text generative model). E.g., in
Table 1, to mislead humans, the entity ‘Relay Ventures’ can be replaced by ‘Samsung’ (a candidate
replacement entity generated by the generative pretraining-2 model (GPT-2) (Radford et al., 2019)),
which is locally consistent as some of the other
companies in the original text are also into device
manufacturing.
To distinguish a manipulated news article from
the original human written news article, we propose
a neural network based detector that jointly utilizes
the textual information along with the the factual
knowledge explicitly by building entity-relation
graphs which capture the relationship between different entities present in the news article. The factual knowledge is encoded by a graph convolutional
neural network (Kipf and Welling, 2017) that captures the interactions between different entities and
relations, which we hypothesize, carries discriminatory signals for the manipulated text detection task.
Our major contributions include: (i) a detector that
exploits factual knowledge to overcome the limitations of relying only on stylometric signals, (ii)
an approach to generate challenging manipulated
news article dataset using GPT-2, and (iii) a collection of challenging datasets by considering various
strategies to generate the replacement entity.
We presented the first principled approach for developing a model that can detect entity-manipulated
text articles. In addition to textual information, our
proposed detector exploits explicit factual knowledge from a knowledge base to overcome the limitations of relying only on stylometric signals. We
constructed challenging manipulated datasets by
considering various entity replacement strategies,
including with random selection and GPT-2 generation. On all the experimental settings, our proposed model outperforms (or is at least on par with)
the baseline detector in overall detection accuracy.
Our results show that manipulated text detection remains challenging. We hope that our work will trigger further research on this important but relatively
understudied subfield of fake news detection.