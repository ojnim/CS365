1 Introduction
Automatic document summarization is the task of
rewriting a long document into its shorter form
while still retaining its most important content. In
the literature, there are mainly two kinds of methods for summarization: extractive summarization
and abstractive summarization (Nenkova and McKeown, 2011). In this work, we focus on abstractive
summarization, which is viewed as a sequence-tosequence (Seq2Seq) learning problem, since recent abstractive models outperform their extractive counterparts and can produce more concise
summaries (Raffel et al., 2020; Lewis et al., 2020;
Zhang et al., 2020; Liu and Lapata, 2019). Recent
progress of abstractive summarization largely relies
on large pre-trained Transformer models (Raffel
et al., 2020; Lewis et al., 2020; Zhang et al., 2020;
Liu and Lapata, 2019; Bao et al., 2020). With these
extremely large models, we can obtain state-of-theart summarization results, but they are slow for
online inference, which makes them difficult to
be used in the production environment even with
cutting-edge hardware. This paper aims to distill
these large Transformer summarization models into
smaller ones with minimal loss in performance.
Knowledge distillation is a class of methods that
leverage the output of a (large) teacher model to
guide the training of a (small) student model. In
classification tasks, it is typically done by minimizing the distance between the teacher and student
predictions (Hinton et al., 2015). As to Seq2Seq
models, an effective distillation method is called
pseudo-labeling (Kim and Rush, 2016), where the
teacher model generates pseudo summaries for all
documents in the training set and the resulting
document–pseudo-summary pairs are used to train
the student model.
In this paper, we argue that attention distributions of a Seq2Seq teacher model might be too
sharp. As a result, pseudo labels generated from
it are sub-optimal for student models. In the summarization task, we observe that 1) pseudo summaries generated from our teacher model copy
more continuous text spans from original documents than reference summaries (56% 4-grams in
pseudo summaries and 15% 4-grams in reference
summaries are copied from their original documents on CNN/DailyMail dataset); 2) pseudo summaries tend to summarize the leading part of a
document (measured on CNN/DailyMail, 74% of
sentences in pseudo summaries and 64% of sentences in reference summaries are from the leading
40% sentences in original documents). We obtain
the two numbers above by matching each sentence
in a summary with the sentence in its original document that can produce maximum ROUGE (Lin,
2004) score between them. We call the two biases above the copy bias and the leading bias. In
order to have an intuitive feeling, we select a representative example 1
and visualize its cross attention weights 2
(see the left graph in Figure 1). We
observe that attention weights form three “lines”,
which indicates very time the decoder predicts the
next word, its attention points to the next word in
the input document. That may be the reason why
multiple continuous spans of text are copied. Another phenomenon we observe is that all high-value
attention weights (in deeper color) concentrate on
the first 200 words in the input document, which
reflects the leading bias. In either case, the attention distribution is too sharp (i.e., attention weights
of the next word position or the leading part is
much larger than other positions), which means our
teacher model is over-confident.
Based on the observations above, we propose a simple method called PLATE (as shorthand for Pseudo-labeling with Larger Attention
TEmperature) to smooth attention distributions of
teacher models. Specifically, we re-scale attention
weights in all attention modules with a higher temperature, which leads to softer attention distributions. Figure 1 intuitively shows the effect of using
higher attention temperatures. Compared with the
left graph, the right graph with higher attention temperature has shorter lines (less copy bias) with high
attention weights, and positions of high attention
weights extend to the first 450 words (less leading
bias). Less copy bias in pseudo summaries encourages student models to be more abstractive, while
less leading bias in pseudo summaries encourages
student models to take advantage of longer context
in documents.
Experiments on CNN/DailyMail, XSum, and
New York Times datasets with student models of
different sizes show PLATE consistently outperforms vanilla pseudo-labeling methods. Further
empirical analysis shows that, with PLATE, both
pseudo summaries generated by teacher models
and summaries generated by student models are
shorter and more abstractive, which matches the
goal of abstractive summarization.

5 Conclusions
In this work, we propose a simple but effective
extension of pseudo-labeling method PLATE for
summarization distillation. Experiments on three
datasets demonstrate that our method can consistently outperform the vanilla pseudo-labeling
method. Further empirical analysis shows that by
using our method, teacher models can generate
more concise and abstractive summaries. As a result, summaries produced by student models also
become more concise and abstractive. In the future, we would like to explore our method to other
generation tasks as well as self-training with unlabeled data. We are also interested in combining our
method with other distillation methods and extending our method for better teacher model training.